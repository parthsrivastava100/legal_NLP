{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=np.load('/../data/legal_NLP/legalNLP_data/final_embd_files/sent2vec_embd_files/final_sv_mincount5_dim200_Vsize250000_Ngram2/train_embd_final_sv_mincount5_dim200_Vsize250000_Ngram2.npy',allow_pickle='true')\n",
    "x_train_data=x[:,0]\n",
    "y_train=x[:,1]\n",
    "y_train=y_train.astype('int')\n",
    "x_train=np.zeros([32305,200])\n",
    "for i in range(0,32305):\n",
    "    b=np.zeros([len(x_train_data[i]),200])\n",
    "    for j in range(0,len(x_train_data[i])):\n",
    "        b[j,:]=x_train_data[i][j]\n",
    "    b=np.sum(b,axis=0)\n",
    "    x_train[i,:]=b/len(x_train_data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32305, 200)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.load('/../data/legal_NLP/legalNLP_data/final_embd_files/sent2vec_embd_files/final_sv_mincount5_dim200_Vsize250000_Ngram2/test_embd_final_sv_mincount5_dim200_Vsize250000_Ngram2.npy',allow_pickle='true')\n",
    "x_test_data=y[:,0]\n",
    "y_test=y[:,1]\n",
    "y_test=y_test.astype('int')\n",
    "x_test=np.zeros([1517,200])\n",
    "for i in range(0,1517):\n",
    "    b=np.zeros([len(x_test_data[i]),200])\n",
    "    for j in range(0,len(x_test_data[i])):\n",
    "        b[j,:]=x_test_data[i][j]\n",
    "    b=np.sum(b,axis=0)\n",
    "    x_test[i,:]=b/len(x_test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=np.load('/../data/legal_NLP/legalNLP_data/final_embd_files/sent2vec_embd_files/final_sv_mincount5_dim200_Vsize250000_Ngram2/validation_embd_final_sv_mincount5_dim200_Vsize250000_Ngram2.npy',allow_pickle='true')\n",
    "x_dev_data=z[:,0]\n",
    "y_dev=z[:,1]\n",
    "y_dev=y_dev.astype('int')\n",
    "x_dev=np.zeros([994,200])\n",
    "for i in range(0,994):\n",
    "    b=np.zeros([len(x_dev_data[i]),200])\n",
    "    for j in range(0,len(x_dev_data[i])):\n",
    "        b[j,:]=x_dev_data[i][j]\n",
    "    b=np.sum(b,axis=0)\n",
    "    x_dev[i,:]=b/len(x_dev_data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.23465343 -0.12870004 -0.12489287 ...  0.05784892  0.04879328\n",
      "   0.18257203]\n",
      " [ 0.0843488  -0.14360571 -0.19869974 ...  0.0475443   0.11492499\n",
      "  -0.06642166]\n",
      " [ 0.15217664 -0.07390564 -0.10769357 ... -0.00774169  0.01975319\n",
      "  -0.06602175]\n",
      " ...\n",
      " [-0.10669029 -0.0455214  -0.0211758  ... -0.00930675  0.11525618\n",
      "   0.043224  ]\n",
      " [ 0.03532715 -0.06977894 -0.06398666 ...  0.03205929 -0.02879568\n",
      "   0.00917467]\n",
      " [ 0.08008892 -0.17394208 -0.11530315 ...  0.0074436   0.0226157\n",
      "  -0.05872493]]\n",
      "(1517,)\n",
      "(994,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(y_test.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1=np.zeros([32305,1])\n",
    "for i in range(0,32305):\n",
    "    y_train1[i][0]=y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1=np.zeros([1517,1])\n",
    "for i in range(0,1517):\n",
    "    y_test1[i][0]=y_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev1=np.zeros([994,1])\n",
    "for i in range(0,994):\n",
    "    y_dev1[i][0]=y_dev[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.23465343 -0.12870004 -0.12489287 ...  0.05784892  0.04879328\n",
      "   0.18257203]\n",
      " [ 0.0843488  -0.14360571 -0.19869974 ...  0.0475443   0.11492499\n",
      "  -0.06642166]\n",
      " [ 0.15217664 -0.07390564 -0.10769357 ... -0.00774169  0.01975319\n",
      "  -0.06602175]\n",
      " ...\n",
      " [-0.10669029 -0.0455214  -0.0211758  ... -0.00930675  0.11525618\n",
      "   0.043224  ]\n",
      " [ 0.03532715 -0.06977894 -0.06398666 ...  0.03205929 -0.02879568\n",
      "   0.00917467]\n",
      " [ 0.08008892 -0.17394208 -0.11530315 ...  0.0074436   0.0226157\n",
      "  -0.05872493]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def metrics_calculator(preds, test_labels):\n",
    "    cm = confusion_matrix(test_labels, preds)\n",
    "    TP = []\n",
    "    FP = []\n",
    "    FN = []\n",
    "    for i in range(0,2):\n",
    "        summ = 0\n",
    "        for j in range(0,2):\n",
    "            if(i!=j):\n",
    "                summ=summ+cm[i][j]\n",
    "\n",
    "        FN.append(summ)\n",
    "    for i in range(0,2):\n",
    "        summ = 0\n",
    "        for j in range(0,2):\n",
    "            if(i!=j):\n",
    "                summ=summ+cm[j][i]\n",
    "\n",
    "        FP.append(summ)\n",
    "    for i in range(0,2):\n",
    "        TP.append(cm[i][i])\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for i in range(0,2):\n",
    "        precision.append(TP[i]/(TP[i] + FP[i]))\n",
    "        recall.append(TP[i]/(TP[i] + FN[i]))\n",
    "\n",
    "    macro_precision = sum(precision)/2\n",
    "    macro_recall = sum(recall)/2\n",
    "    micro_precision = sum(TP)/(sum(TP) + sum(FP))\n",
    "    micro_recall = sum(TP)/(sum(TP) + sum(FN))\n",
    "    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision + micro_recall)\n",
    "    macro_f1 = (2*macro_precision*macro_recall)/(macro_precision + macro_recall)\n",
    "    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1\n",
    "def RF_scores(train_avg, dev_avg, test_avg, train_labels, dev_labels, test_labels):\n",
    "    f = open(\"RF_results.txt\", \"w+\")\n",
    "    f.write(\"Varying the n_estimators from 50 to 500\\n\\n\")\n",
    "    for n_est in range(50,500,50):\n",
    "        clf=RandomForestClassifier(n_estimators=n_est)\n",
    "        clf.fit(train_avg,train_labels)\n",
    "        d_preds = clf.predict(dev_avg)\n",
    "        Heading = \"For n_estimators: \" + str(n_est) + \"\\n\"\n",
    "        d_res = \"Accuracy -> \" + str(accuracy_score(d_preds, dev_labels)*100) + \"\\n\"\n",
    "        macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(d_preds, dev_labels)\n",
    "        d_metrics = \"Micros : \" + str(micro_precision) + \" \" + str(micro_recall) + \" \" + str(micro_f1) + \" Macros: \" + str(macro_precision) + \" \" + str(macro_recall) + \" \" + str(macro_f1) + \"\\n\"\n",
    "        f.write(Heading + \"Dev set:\\n\"+ d_res + d_metrics)\n",
    "        \n",
    "        t_preds = clf.predict(test_avg)\n",
    "        t_res = \"Accuracy -> \" + str(accuracy_score(t_preds, test_labels)*100) + \"\\n\"\n",
    "        macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(t_preds, test_labels)\n",
    "        t_metrics = \"Micros : \" + str(micro_precision) + \" \" + str(micro_recall) + \" \" + str(micro_f1) + \" Macros: \" + str(macro_precision) + \" \" + str(macro_recall) + \" \" + str(macro_f1) + \"\\n\"\n",
    "        f.write(\"Test set:\\n\"+ t_res + t_metrics + \"\\n\\n\")\n",
    "        \n",
    "    f.close()\n",
    "def LR_scores(train_avg, dev_avg, test_avg, train_labels, dev_labels, test_labels):\n",
    "    f = open(\"LR_results.txt\", \"w+\")\n",
    "    f.write(\"Varying the max_iters from 50 to 500\\n\\n\")\n",
    "    for it in range(50,500,50):\n",
    "        LR = LogisticRegression(C=1, max_iter =it)\n",
    "        LR.fit(train_avg, train_labels)\n",
    "        d_preds = LR.predict(dev_avg)\n",
    "        Heading = \"For max_iters: \" + str(it) + \"\\n\"\n",
    "        d_res = \"Accuracy -> \" + str(accuracy_score(d_preds, dev_labels)*100) + \"\\n\"\n",
    "        macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(d_preds, dev_labels)\n",
    "        d_metrics = \"Micros : \" + str(micro_precision) + \" \" + str(micro_recall) + \" \" + str(micro_f1) + \" Macros: \" + str(macro_precision) + \" \" + str(macro_recall) + \" \" + str(macro_f1) + \"\\n\"\n",
    "        f.write(Heading + \"Dev set:\\n\"+ d_res + d_metrics)\n",
    "        \n",
    "        t_preds = LR.predict(test_avg)\n",
    "        t_res = \"Accuracy -> \" + str(accuracy_score(t_preds, test_labels)*100) + \"\\n\"\n",
    "        macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(t_preds, test_labels)\n",
    "        t_metrics = \"Micros : \" + str(micro_precision) + \" \" + str(micro_recall) + \" \" + str(micro_f1) + \" Macros: \" + str(macro_precision) + \" \" + str(macro_recall) + \" \" + str(macro_f1) + \"\\n\"\n",
    "        f.write(\"Test set:\\n\"+ t_res + t_metrics + \"\\n\\n\")\n",
    "        \n",
    "    f.close()\n",
    "def SVM_scores(train_avg, dev_avg, test_avg, train_labels, dev_labels, test_labels):\n",
    "    f = open(\"SVM_results.txt\", \"w+\")\n",
    "    f.write(\"Varying the kernels: \\n\\n\")\n",
    "    kers = [\"linear\", \"poly\", \"rbf\"]\n",
    "    for k in kers:\n",
    "        print(\"Running for {0}\".format(k))\n",
    "        SVM = svm.SVC(C=1, kernel=k)\n",
    "        SVM.fit(train_avg, train_labels)\n",
    "        d_preds = SVM.predict(dev_avg)\n",
    "        Heading = \"For kernel: \" + k + \"\\n\"\n",
    "        d_res = \"Accuracy -> \" + str(accuracy_score(d_preds, dev_labels)*100) + \"\\n\"\n",
    "        macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(d_preds, dev_labels)\n",
    "        d_metrics = \"Micros : \" + str(micro_precision) + \" \" + str(micro_recall) + \" \" + str(micro_f1) + \" Macros: \" + str(macro_precision) + \" \" + str(macro_recall) + \" \" + str(macro_f1) + \"\\n\"\n",
    "        f.write(Heading + \"Dev set:\\n\"+ d_res + d_metrics)\n",
    "        print(Heading + \"Dev set:\\n\"+ d_res + d_metrics)\n",
    "\n",
    "        t_preds = SVM.predict(test_avg)\n",
    "        t_res = \"Accuracy -> \" + str(accuracy_score(t_preds, test_labels)*100) + \"\\n\"\n",
    "        macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(t_preds, test_labels)\n",
    "        t_metrics = \"Micros : \" + str(micro_precision) + \" \" + str(micro_recall) + \" \" + str(micro_f1) + \" Macros: \" + str(macro_precision) + \" \" + str(macro_recall) + \" \" + str(macro_f1) + \"\\n\"\n",
    "        f.write(\"Test set:\\n\"+ t_res + t_metrics + \"\\n\\n\")\n",
    "        print(\"Test set:\\n\"+ t_res + t_metrics + \"\\n\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "SVM_scores(x_train,x_dev,x_test,y_train1,y_dev1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}